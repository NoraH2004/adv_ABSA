{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for crafting Adversarial Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbation Methods\n",
    "#### 1. leet speak & unicode\n",
    "#### 2. typos\n",
    "#### 3. punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import utils.text_processing as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from important word detector\n",
    "%store -r important_words_packages\n",
    "%store -r sentence_packages\n",
    "%store -r loo_results\n",
    "\n",
    "%store -r important_words_packages_dev\n",
    "%store -r sentence_packages_dev\n",
    "%store -r loo_results_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important_words_packages = important_words_packages_dev\n",
    "#sentence_packages = sentence_packages_dev\n",
    "#loo_results = loo_results_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M3th0d 1: 133t 5p34k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create modified Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get original sentences from sentence_packages\n",
    "original_sentences = []\n",
    "for package in sentence_packages:\n",
    "    original_sentences.append(package['original_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate modified words: take Important Words and conduct modification\n",
    "\n",
    "modified_words_packages = []\n",
    "\n",
    "for important_words in important_words_packages:\n",
    "    modified_words = []\n",
    "    \n",
    "    for word in important_words:\n",
    "        modified_word_variances = []\n",
    "        modified_word_variances.append(tp.to_leet(word))\n",
    "        modified_words.append(modified_word_variances)\n",
    "\n",
    "    modified_words_packages.append(modified_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate modified sentences\n",
    "modifyable_original_sentences, modified_sentence_packages, number_of_modified_sentences = tp.generate_modified_sentence_packages(original_sentences, important_words_packages, modified_words_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of original sentences: 8\n",
      "Total number of modifyable original sentences:  7\n",
      "Total number of modified sentences:  11\n"
     ]
    }
   ],
   "source": [
    "print('Total number of original sentences:', len(original_sentences))\n",
    "print('Total number of modifyable original sentences: ', len(modifyable_original_sentences))\n",
    "print('Total number of modified sentences: ', number_of_modified_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Import BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get individual key from key file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = open(\"security/key.txt\", \"r\")\n",
    "key = k.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Predictor\n",
      "Loading model models/en-laptops-absa\n",
      "Config loaded from models/en-laptops-absa/config.json\n",
      "Aspects loaded from models/en-laptops-absa/aspects.jsonl\n",
      "Config loaded from models/en-laptops-absa/config.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import spacy\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "\n",
    "from absa import Predictor\n",
    "from security import Authorization\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "pred = Predictor(os.path.join('models','en-laptops-absa'))\n",
    "\n",
    "!export CUDA_VISIBLE_DEVICE=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Prediction\n",
    "\n",
    "###### Original Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for sentence in modifyable_original_sentences:\n",
    "    document = {'text': sentence, 'segments':[{'span':[0,0],'text': sentence}]}\n",
    "    documents.append(document)\n",
    "    \n",
    "results = pred.predict(documents, key, with_segments=True)\n",
    "\n",
    "original_predictions = []\n",
    "for result in results:\n",
    "    original_predictions.append(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    }
   ],
   "source": [
    "# 1. create indices for prediction,\n",
    "# 2. flatten modified_sentence_packages and \n",
    "# 3. predict flattened list\n",
    "\n",
    "results = []\n",
    "documents = []\n",
    "package_indices = []\n",
    "package_index = 0\n",
    "for sentence in modified_sentence_packages:\n",
    "    package_index += 1\n",
    "    for word in sentence:\n",
    "        for variant in word:  \n",
    "            package_indices.append(package_index)\n",
    "            document = {'text': variant, 'segments':[{'span':[0,0],'text': variant}]}\n",
    "            documents.append(document)\n",
    "    \n",
    "results = pred.predict(documents, key, with_segments=True)\n",
    "\n",
    "modified_results_flattened = []\n",
    "for result in results:\n",
    "    modified_results_flattened.append(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. map to lvl2 sentence packages\n",
    "# IMPORTANT: here I loose the last variants level because I do not actually need it\n",
    "# todo: loose levels --> only have one level per sentence when generating modified sentence packages\n",
    "\n",
    "modified_predictions = []\n",
    "modified_sentence = []\n",
    "check = 1\n",
    "for e, result in enumerate(modified_results_flattened):\n",
    "    i = package_indices[e]    \n",
    "    if i == check:\n",
    "        modified_sentence.append(result)\n",
    "    else:\n",
    "        modified_predictions.append(modified_sentence)\n",
    "        modified_sentence = []\n",
    "        modified_sentence.append(result)\n",
    "    check = i\n",
    "modified_predictions.append(modified_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparison of results to check effectiveness of attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "leet_results = tp.compare_results(original_predictions, modified_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creation of adversarial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_texts, original_results, modified_texts, modified_results, successfull_modifications = tp.generate_results_lists(leet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_dataset = pd.DataFrame(list(zip(original_texts, original_results, modified_texts, modified_results)),\n",
    "                 columns = ['original_sentence', 'original_prediction', 'modified_sentence', 'modified_prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_dataset.to_json(r'data/adversarial_dataset_l33t.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_sentence</th>\n",
       "      <th>original_prediction</th>\n",
       "      <th>modified_sentence</th>\n",
       "      <th>modified_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>super fast processor and really nice graphics ...</td>\n",
       "      <td>[{'aspect': 'Graphics', 'sentiment': 'POS'}, {...</td>\n",
       "      <td>[super f45t processor and really nice graphics...</td>\n",
       "      <td>[[{'aspect': 'Graphics', 'sentiment': 'POS'}, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and plenty of storage with 250 gb(though I wil...</td>\n",
       "      <td>[{'aspect': 'Storage', 'sentiment': 'POS'}]</td>\n",
       "      <td>[and plenty of 5t0r4g3 with 250 gb(though I wi...</td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This computer is really fast and I'm shocked a...</td>\n",
       "      <td>[{'aspect': 'Performance', 'sentiment': 'POS'}]</td>\n",
       "      <td>[This computer is really f45t and I'm shocked ...</td>\n",
       "      <td>[[{'aspect': 'Laptop (general)', 'sentiment': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i would really recommend to any person out the...</td>\n",
       "      <td>[{'aspect': 'Laptop (general)', 'sentiment': '...</td>\n",
       "      <td>[i would really recommend to any person out th...</td>\n",
       "      <td>[[{'aspect': 'Laptop (general)', 'sentiment': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and its really cheap and you wont regret buyin...</td>\n",
       "      <td>[{'aspect': 'Laptop (general)', 'sentiment': '...</td>\n",
       "      <td>[and its really ch34p and you wont regret buyi...</td>\n",
       "      <td>[[{'aspect': 'Laptop (general)', 'sentiment': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   original_sentence  \\\n",
       "0  super fast processor and really nice graphics ...   \n",
       "1  and plenty of storage with 250 gb(though I wil...   \n",
       "2  This computer is really fast and I'm shocked a...   \n",
       "3  i would really recommend to any person out the...   \n",
       "4  and its really cheap and you wont regret buyin...   \n",
       "\n",
       "                                 original_prediction  \\\n",
       "0  [{'aspect': 'Graphics', 'sentiment': 'POS'}, {...   \n",
       "1        [{'aspect': 'Storage', 'sentiment': 'POS'}]   \n",
       "2    [{'aspect': 'Performance', 'sentiment': 'POS'}]   \n",
       "3  [{'aspect': 'Laptop (general)', 'sentiment': '...   \n",
       "4  [{'aspect': 'Laptop (general)', 'sentiment': '...   \n",
       "\n",
       "                                   modified_sentence  \\\n",
       "0  [super f45t processor and really nice graphics...   \n",
       "1  [and plenty of 5t0r4g3 with 250 gb(though I wi...   \n",
       "2  [This computer is really f45t and I'm shocked ...   \n",
       "3  [i would really recommend to any person out th...   \n",
       "4  [and its really ch34p and you wont regret buyi...   \n",
       "\n",
       "                                 modified_prediction  \n",
       "0  [[{'aspect': 'Graphics', 'sentiment': 'POS'}, ...  \n",
       "1                                               [[]]  \n",
       "2  [[{'aspect': 'Laptop (general)', 'sentiment': ...  \n",
       "3  [[{'aspect': 'Laptop (general)', 'sentiment': ...  \n",
       "4  [[{'aspect': 'Laptop (general)', 'sentiment': ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 790 entries, 0 to 789\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   original_sentence    790 non-null    object\n",
      " 1   original_prediction  790 non-null    object\n",
      " 2   modified_sentence    790 non-null    object\n",
      " 3   modified_prediction  790 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 24.8+ KB\n"
     ]
    }
   ],
   "source": [
    "adversarial_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table_leet = tp.generate_results_df(original_sentences, modifyable_original_sentences, number_of_modified_sentences, successfull_modifications, pmethod='leet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'results_table_leet' (DataFrame)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Perturbation Method</th>\n",
       "      <td>leet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokenizer</th>\n",
       "      <td>en_core_web_sm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <td>en-laptops-absa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <td>SemEval 2015 Laptops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total number of original sentences</th>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total number of modifyable original sentences</th>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total number of modified sentences</th>\n",
       "      <td>2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total number of changed predictions through modification</th>\n",
       "      <td>1702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Success Rate</th>\n",
       "      <td>0.762545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       0\n",
       "Perturbation Method                                                 leet\n",
       "Tokenizer                                                 en_core_web_sm\n",
       "Model                                                    en-laptops-absa\n",
       "Dataset                                             SemEval 2015 Laptops\n",
       "Total number of original sentences                                   943\n",
       "Total number of modifyable original sentences                        897\n",
       "Total number of modified sentences                                  2232\n",
       "Total number of changed predictions through mod...                  1702\n",
       "Success Rate                                                    0.762545"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store results_table_leet\n",
    "results_table_leet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = confusion_matrix(original_predictions, modified_predictions)\n",
    "df_cm = pd.DataFrame(array, range(5), range(5))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, fmt=\"d\", linewidths=.1) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
