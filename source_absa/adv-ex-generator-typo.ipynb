{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for crafting Adversarial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-917d698f5e50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import utils.text_processing as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from important word detector\n",
    "%store -r important_words_packages\n",
    "%store -r sentence_packages\n",
    "%store -r loo_results\n",
    "\n",
    "%store -r important_words_packages_dev\n",
    "%store -r sentence_packages_dev\n",
    "%store -r loo_results_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important_words_packages = important_words_packages_dev\n",
    "#sentence_packages = sentence_packages_dev\n",
    "#loo_results = loo_results_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methed 2: Mispeeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create Typo-Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data','common_typos_wikipedia.txt'), 'r') as f:\n",
    "    typods = f.readlines()\n",
    "\n",
    "typodict = {}\n",
    "      \n",
    "for typod in typods:  \n",
    "    typo = typod.split(\"->\")[0].strip('\\n')\n",
    "    word = typod.split(\"->\")[1].strip('\\n')\n",
    " \n",
    "    for item in word.split(\", \"):\n",
    "        if item in typodict:\n",
    "            tmp_typo = typodict[item]\n",
    "            tmp_typo.append(typo)             \n",
    "            tmp_typo = list(set(tmp_typo)) #filter duplicates\n",
    "            typodict[item] = tmp_typo\n",
    "        else:\n",
    "            typodict.update({item : [typo]})\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get original sentences from sentence_packages\n",
    "original_sentences = []\n",
    "for package in sentence_packages:\n",
    "    original_sentences.append(package['original_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate modified words: take Important Words and conduct modification\n",
    "\n",
    "modified_words_packages = []\n",
    "\n",
    "for important_words in important_words_packages:\n",
    "    modified_words = []\n",
    "    \n",
    "    for word in important_words:\n",
    "        modified_word_variances = []\n",
    "        modified_word_variances.append(tp.to_typo(typodict, word))\n",
    "        modified_words.append(modified_word_variances)\n",
    "\n",
    "    modified_words_packages.append(modified_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate modified sentences\n",
    "modifyable_original_sentences, modified_sentence_packages, number_of_modified_sentences = tp.generate_modified_sentence_packages(original_sentences, important_words_packages, modified_words_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of original sentences: 943\n",
      "Total number of modifyable original sentences:  369\n",
      "Total number of modified sentences:  1354\n"
     ]
    }
   ],
   "source": [
    "print('Total number of original sentences:', len(original_sentences))\n",
    "print('Total number of modifyable original sentences: ', len(modifyable_original_sentences))\n",
    "print('Total number of modified sentences: ', number_of_modified_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Import BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = open(\"security/key.txt\", \"r\")\n",
    "key = k.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Predictor\n",
      "Loading model models/en-laptops-absa\n",
      "Config loaded from models/en-laptops-absa/config.json\n",
      "Aspects loaded from models/en-laptops-absa/aspects.jsonl\n",
      "Config loaded from models/en-laptops-absa/config.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import spacy\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "\n",
    "from absa import Predictor\n",
    "from security import Authorization\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "pred = Predictor(os.path.join('models','en-laptops-absa'))\n",
    "\n",
    "!export CUDA_VISIBLE_DEVICE=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Prediction\n",
    "\n",
    "###### Original Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for sentence in modifyable_original_sentences:\n",
    "    document = {'text': sentence, 'segments':[{'span':[0,0],'text': sentence}]}\n",
    "    documents.append(document)\n",
    "    \n",
    "results = pred.predict(documents, key, with_segments=True)\n",
    "\n",
    "original_predictions = []\n",
    "for result in results:\n",
    "    original_predictions.append(result[0])\n",
    "#print(original_predictions)\n",
    "print(len(original_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modified Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1354\n"
     ]
    }
   ],
   "source": [
    "# 1. create indices for prediction,\n",
    "# 2. flatten modified_sentence_packages and \n",
    "# 3. predict flattened list\n",
    "\n",
    "results = []\n",
    "documents = []\n",
    "package_indices = []\n",
    "package_index = 0\n",
    "for sentence in modified_sentence_packages:\n",
    "    package_index += 1\n",
    "    for word in sentence:\n",
    "        for variant in word:  \n",
    "            package_indices.append(package_index)\n",
    "            document = {'text': variant, 'segments':[{'span':[0,0],'text': variant}]}\n",
    "            documents.append(document)\n",
    "    \n",
    "results = pred.predict(documents, key, with_segments=True)\n",
    "\n",
    "modified_results_flattened = []\n",
    "for result in results:\n",
    "    modified_results_flattened.append(result[0])\n",
    "\n",
    "#print(modified_results_flattened)\n",
    "print(len(modified_results_flattened))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. map to lvl2 sentence packages\n",
    "# IMPORTANT: here I loose the last variants level because I do not actually need it\n",
    "# todo: loose levels --> only have one level per sentence when generating modified sentence packages\n",
    "\n",
    "modified_predictions = []\n",
    "modified_sentence = []\n",
    "check = 1\n",
    "for e, result in enumerate(modified_results_flattened):\n",
    "    i = package_indices[e]    \n",
    "    if i == check:\n",
    "        modified_sentence.append(result)\n",
    "    else:\n",
    "        modified_predictions.append(modified_sentence)\n",
    "        modified_sentence = []\n",
    "        modified_sentence.append(result)\n",
    "    check = i\n",
    "modified_predictions.append(modified_sentence)\n",
    "#print(modified_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparison of results to check effectiveness of attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "typo_results = tp.compare_results(original_predictions, modified_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create adversarial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_texts, original_results, modified_texts, modified_results, successfull_modifications = tp.generate_results_lists(typo_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_dataset = pd.DataFrame(list(zip(original_texts, original_results, modified_texts, modified_results)),\n",
    "                 columns = ['original_sentence', 'original_prediction', 'modified_sentence', 'modified_prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 259 entries, 0 to 258\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   original_sentence    259 non-null    object\n",
      " 1   original_prediction  259 non-null    object\n",
      " 2   modified_sentence    259 non-null    object\n",
      " 3   modified_prediction  259 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 8.2+ KB\n"
     ]
    }
   ],
   "source": [
    "adversarial_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_sentence</th>\n",
       "      <th>original_prediction</th>\n",
       "      <th>modified_sentence</th>\n",
       "      <th>modified_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oh my goodness-I am not a happy camper.</td>\n",
       "      <td>[{'aspect': 'Laptop (general)', 'sentiment': '...</td>\n",
       "      <td>[Oh my goodness-I am nto a happy camper., Oh m...</td>\n",
       "      <td>[[{'aspect': 'Laptop (general)', 'sentiment': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I returned the computer to HP and they kept it...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[I returned the computer to HP and htey kept i...</td>\n",
       "      <td>[[{'aspect': 'Laptop (general)', 'sentiment': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When I got the computer back and realizwed it ...</td>\n",
       "      <td>[{'aspect': 'Laptop (general)', 'sentiment': '...</td>\n",
       "      <td>[When I got the cmoputer back and realizwed it...</td>\n",
       "      <td>[[], [], [], []]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Currently if I use the laptop I can't sit it o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Currently if I uise the laptop I can't sit it...</td>\n",
       "      <td>[[{'aspect': 'Temperature', 'sentiment': 'NEG'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The screen takes some getting use to, because ...</td>\n",
       "      <td>[{'aspect': 'Screen', 'sentiment': 'NEG'}, {'a...</td>\n",
       "      <td>[The screen takes some getting use to, because...</td>\n",
       "      <td>[[{'aspect': 'Screen', 'sentiment': 'NEG'}], [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   original_sentence  \\\n",
       "0            Oh my goodness-I am not a happy camper.   \n",
       "1  I returned the computer to HP and they kept it...   \n",
       "2  When I got the computer back and realizwed it ...   \n",
       "3  Currently if I use the laptop I can't sit it o...   \n",
       "4  The screen takes some getting use to, because ...   \n",
       "\n",
       "                                 original_prediction  \\\n",
       "0  [{'aspect': 'Laptop (general)', 'sentiment': '...   \n",
       "1                                                 []   \n",
       "2  [{'aspect': 'Laptop (general)', 'sentiment': '...   \n",
       "3                                                 []   \n",
       "4  [{'aspect': 'Screen', 'sentiment': 'NEG'}, {'a...   \n",
       "\n",
       "                                   modified_sentence  \\\n",
       "0  [Oh my goodness-I am nto a happy camper., Oh m...   \n",
       "1  [I returned the computer to HP and htey kept i...   \n",
       "2  [When I got the cmoputer back and realizwed it...   \n",
       "3  [Currently if I uise the laptop I can't sit it...   \n",
       "4  [The screen takes some getting use to, because...   \n",
       "\n",
       "                                 modified_prediction  \n",
       "0  [[{'aspect': 'Laptop (general)', 'sentiment': ...  \n",
       "1  [[{'aspect': 'Laptop (general)', 'sentiment': ...  \n",
       "2                                   [[], [], [], []]  \n",
       "3  [[{'aspect': 'Temperature', 'sentiment': 'NEG'...  \n",
       "4  [[{'aspect': 'Screen', 'sentiment': 'NEG'}], [...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'adversarial_dataset' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store adversarial_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_dataset.to_json(r'data/adversarial_dataset_multitypos.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Resluts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table_typo = tp.generate_results_df(original_sentences, modifyable_original_sentences, number_of_modified_sentences, successfull_modifications, pmethod='typos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'results_table_typo' (DataFrame)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Perturbation Method</th>\n",
       "      <td>typos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokenizer</th>\n",
       "      <td>en_core_web_sm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <td>en-laptops-absa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <td>SemEval 2015 Laptops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total number of original sentences</th>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total number of modifyable original sentences</th>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total number of modified sentences</th>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total number of changed predictions through modification</th>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Success Rate</th>\n",
       "      <td>0.557607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       0\n",
       "Perturbation Method                                                typos\n",
       "Tokenizer                                                 en_core_web_sm\n",
       "Model                                                    en-laptops-absa\n",
       "Dataset                                             SemEval 2015 Laptops\n",
       "Total number of original sentences                                   943\n",
       "Total number of modifyable original sentences                        369\n",
       "Total number of modified sentences                                  1354\n",
       "Total number of changed predictions through mod...                   755\n",
       "Success Rate                                                    0.557607"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store results_table_typo\n",
    "results_table_typo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_original_results, extended_modified_results = tp.generate_multipredictions(original_results, modified_results)\n",
    "\n",
    "# asp_map = [('Graphics', 'POS'), ....]\n",
    "# for eor in extended_results:\n",
    "# tuple = (kv['aspect'], kv['sentiment']) => asp_map.index(tuple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_aspsent_map_dict(results_dict):\n",
    "    # check, which aspects and sentiments are in the data\n",
    "\n",
    "    aspects_sentiments = []\n",
    "\n",
    "    for item in results_dict:\n",
    "        print(item)\n",
    "        tpl = (result['aspect'],result['sentiment'])\n",
    "        print(tpl)\n",
    "        if tpl not in aspects_sentiments:\n",
    "            aspects_sentiments.append(tpl)\n",
    "\n",
    "    return aspects_sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original_sentence': 'super fast processor and really nice graphics card..', 'original_result': [{'aspect': 'Graphics', 'sentiment': 'POS'}, {'aspect': 'CPU', 'sentiment': 'POS'}, {'aspect': 'Performance', 'sentiment': 'POS'}], 'modified_sentences': [['super processor and really nice graphics card..', 'super fast and really nice graphics card..']], 'modified_results': [[[{'aspect': 'Graphics', 'sentiment': 'POS'}, {'aspect': 'CPU', 'sentiment': 'POS'}], [{'aspect': 'Graphics', 'sentiment': 'POS'}, {'aspect': 'Performance', 'sentiment': 'POS'}]]]}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'aspect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-9c6b683a3d38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maspsntmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_aspsent_map_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloo_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#aspsntmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-dd258ccc48fb>\u001b[0m in \u001b[0;36mgenerate_aspsent_map_dict\u001b[0;34m(results_dict)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aspect'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtpl\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maspects_sentiments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'aspect'"
     ]
    }
   ],
   "source": [
    "aspsntmap = generate_aspsent_map_dict(loo_results)\n",
    "#aspsntmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects_sentiments_map_modified = []\n",
    "for emr in extended_modified_results:\n",
    "    for result in emr:\n",
    "        print(result)\n",
    "        result_tuple = (result['aspect'], result['sentiment'])\n",
    "        idx = asp_sent_map.index(result_tuple)\n",
    "        print(idx)\n",
    "        #aspects_sentiments_map_modified.append(asp_sent_map.index(result_tuple))\n",
    "        \n",
    "        \n",
    "print(aspects_sentiments_map_modified)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects_sentiments_original = []\n",
    "for item in extended_original_results:\n",
    "    for result in item:\n",
    "        aspect_sentiment = []\n",
    "        aspect_sentiment.append(result.get('aspect'))\n",
    "        aspect_sentiment.append(result.get('sentiment'))\n",
    "        aspects_sentiments_original.append(aspect_sentiment)\n",
    "        \n",
    "print(aspects_sentiments_original)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'go' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0e3db4081546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fig = go.Figure(data=[go.Sankey(\n\u001b[0m\u001b[1;32m      2\u001b[0m     node = dict(\n\u001b[1;32m      3\u001b[0m       \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mthickness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"black\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'go' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label = [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"],\n",
    "      color = \"brown\"\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = [0, 1, 0, 2, 3, 3], # indices correspond to labels, eg A1, A2, A2, B1, ...\n",
    "      target = [2, 3, 3, 4, 4, 5],\n",
    "      value = [8, 4, 2, 8, 4, 2]\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"Basic Sankey Diagram\", font_size=10)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
